---
layout: post
title: (발번역)딥러닝의 한계들
comments: true
---

_원문 : [https://blog.keras.io/the-limitations-of-deep-learning.html)_

*이 글은 [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff) Chapter 9의 Section 2의 내용을 각색하였다. 딥러닝의 현재 한계와 미래에 대한 2개의 시리즈 글 중에 하나이다.*

*이 글은 딥러닝으로 의미있는 경험을 해보고 사전 지식이 어느정도 있는 사람들에게 맞춰져 있다.*

# 딥러닝:기하학적 관점(the geometric view)
딥러닝 관련해서 가장 놀라운 점은 그것이 굉장히 간단하다는 것이다. 10년전, 어느 누구도 우리는 기계 인식 분야에서 경사하강으로 트레이닝된 간단한 파라미터 모델을 사용해서 이러한 놀라운 결과를 쌓을 것이라고 기대하지 않았다. 현재, 당신이 필요로하는 모든 것들이 충분히 많은 예제에서 경사하강법으로 트레이닝된 충분히 큰 파라미터 모델들이 나오고 있다. 파인먼(Feynman, 미국 물리학자)이 이 우주에 대해 한번 말한적이 있다. *"복잡한게 아니라, 단지 많은 것 뿐이다".*

딥러닝에서 모든것은 벡터(vector)이다. 모든 것들이 *기하학적인 공간의 한 점*인 것처럼. 입력 모델(텍스트, 이미지 등)과 타겟들은 먼저 "벡터화"되어, 즉 초기 입력 벡터 공간 및 타겟 벡터 공간으로 바뀐다. 딥러닝 모델의 각 계층(layer)은 이를 통과하는 데이터들에 대해 간단한 기하학적 변환(geometirc transformation)을 수행한다. 그와 함께 모델 계층들의 체인은 하나의 매우 복잡한 기하학적 변환을 형성하며 일련의 단순한 변환으로 나뉜다. 이 복잡한 변환은 한번에 한 지점씩 입력 공간이 타겟 공간으로 매핑되도록 한다. 이 변환은 모델이 현재 어떻게 수행되는지에 따라 반복적으로 갱신되어지는 계층들의 가중치로 매개변수화된다. 기하학적 변환의 핵심 특징은 경사하강을 통해 매개 변수들을 학습할 수 있어야 한다는 점에서 *차별화*되어야 한다. 즉, 입력부터 출력까지의 기하학적 형태가 매끄럽고 연속적이어야 하는 중요한 제약이 있다.

입력 데이터에 대한 복잡한 기하학적 변형을 적용하는 전체 프로세스는 사람들이 페이퍼볼(paper ball, 종이를 구겨서 만든 공)을  펴는 모습을 상상하듯이 3차원으로 시각화 되어질 수 있다(구겨진 페이퍼볼은 모델이 시작될때 사용되는 다양한 입력 데이터라고 볼 수 있다). 페이퍼볼을 가지고 사람들이 조작하는 각 움직임들은 한 계층에 의해 수행되는 단순한 기하학적인 변환과 유사하다. 완전히 펴지게 하는 움직임들은 전체 모델의 복잡한 변환이다. 딥러닝 모델들은 복잡한 수많은 고차원 데이터를 펴기 위한 수학적 기계이다.

이것이 딥러닝의 마술이다. 의미를 벡터로 변환하고, 기하 공간으로 변환한 다음 한 공간에서 다른 공간으로 매핑하는 복잡한 기학학적인 변환들을 점진적으로 학습한다. 당신이 필요한 것들은 원본 데이터 안에서 발견된 관계들의 모든 범위를 캡쳐하기 위한 충분히 높은 차원의 공간들 뿐이다.

# 딥러닝의 한계들
